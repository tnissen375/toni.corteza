---
- name: Register nginx.conf file
  stat:
    path: "{{ nginx_conf_dir }}/nginx.conf"
  register: nginx_conf_file

- file:
    state: directory
    path: "{{ item }}"
    recurse: yes
  loop:
    "{{ dir_exists }}"

- name: Deploy .env
  template:
    src: ".env.j2"
    dest: "{{ user_path }}/{{ deploy_name }}/.env"
  when: nginx_conf_file.stat.exists

- name: Deploy vscode debug conf
  template:
    src: "launch.json.j2"
    dest: "{{ user_path }}/{{ deploy_name }}/launch.json"
  tags: [ never, dev]
  when: nginx_conf_file.stat.exists

#/proc/sys/kernel/yama/ptrace_scope
- name: Ptrace for go debug
  sysctl:
    name: kernel.yama.ptrace_scope
    value: "0"
    sysctl_set: yes
    state: present
    reload: yes
  tags: [ never, dev]

# - name: Deploy backup script
#   template:
#     src: "backup.sh.j2"
#     dest: "{{ user_path }}/{{ deploy_name }}/backup/backup.sh"
#     mode: u+x

- name: Deploy Make
  template:
    src: "Makefile.j2"
    dest: "{{ user_path }}/{{ deploy_name }}/Makefile"

- name: Git checkout corteza code
  git:
    repo: "{{ corteza_dev_repository }}"
    dest: "{{ srcpath }}"
    version: "{{ corteza_dev_version }}"
    force: yes
  tags: [ never, dev]

- name: Create network
  include_role:
    name: toni.docker
    tasks_from: create_network
  vars:
    ipam_driver_options:
      encrypted: "false"
    docker_networks:
      - { name: "{{ stack_network_name }}", subnet: "{{ stack_subnet }}", driver: "overlay", internal: 'no', gateway: "" }
  when: create_stack_network|default(false)

- name: Deploy vhost
  template:
    src: nginx.conf.j2
    dest: "{{ nginx_conf_dir }}/conf.d/{{ external_domain }}.conf"
  when: nginx_conf_file.stat.exists

- name: Copy snippets
  include_role:
    name: toni.openresty
    tasks_from: snippets
  vars:
    keycloak_access_group: "{{ access_group }}"
    nginx_snippets:
      - { srcname: "auth.conf.j2", destname: "{{ access_group }}_auth.conf" }

- name: Configure nginx logs
  when: nginx_conf_file.stat.exists
  include_role:
    name: toni.openresty
    tasks_from: logs

- name: Register image file
  when: build_local|bool == true
  stat:
    path: "{{ user_path }}/{{ image_file_go_dev_ssh }}"
  register: image_file
  tags: [ never, dev]

- name: remove images
  when: force_images|default(false) and build_local|bool == true
  docker_image:
    name: "{{ image_go_dev_ssh }}"
    force_absent: yes
    state: absent
  tags: [ never, dev]

- name: copy tarball to host
  when: build_local|bool == true and not image_file.stat.exists or force_images|default(false)
  copy:
    src: "/{{ user }}/{{ image_file_go_dev_ssh }}"
    dest: "{{ user_path }}/{{ image_file_go_dev_ssh }}"
  tags: [ never, dev]

- name: load container from tarball
  when: build_local|bool == true
  docker_image:
    name: "{{ image_go_dev_ssh }}"
    load_path: "{{ user_path }}/{{ image_file_go_dev_ssh }}"
    state: present
    source: load
  tags: [ never, dev]

- name: Register image file
  when: build_local|bool == true
  stat:
    path: "{{ user_path }}/{{ image_file_node_ssh }}"
  register: image_file
  tags: [ never, app]

- name: remove images
  when: build_local|bool == true and force_images|default(false)
  docker_image:
    name: "{{ image_node_ssh }}"
    force_absent: yes
    state: absent
  tags: [ never, app]

- name: copy tarball to host
  when: build_local|bool == true and not image_file.stat.exists or force_images|default(false)
  copy:
    src: "/{{ user }}/{{ image_file_node_ssh }}"
    dest: "{{ user_path }}/{{ image_file_node_ssh }}"
  tags: [ never, app]

- name: load container from tarball
  when: build_local|bool == true
  docker_image:
    name: "{{ image_node_ssh }}"
    load_path: "{{ user_path }}/{{ image_file_node_ssh }}"
    state: present
    source: load
  tags: [ never, app]

- name: stop nginx stack
  when: nginx_stack_keep_alive|bool == false
  docker_stack:
    state: absent
    name: "{{ nginx_stack }}"
    compose:
      - "{{ user_path }}/{{ nginx_stack }}/docker-compose.yml"

- name: restart nginx stack
  when: nginx_stack_keep_alive|bool == false
  docker_stack:
    state: present
    prune: yes
    name: "{{ nginx_stack }}"
    compose:
      - "{{ user_path }}/{{ nginx_stack }}/docker-compose.yml"

- name: reload nginx stack
  command: make reload
  args:
    chdir: "{{ user_path }}/{{ nginx_stack }}"
  register: result_reload
  when: nginx_stack_keep_alive|bool == true

- name: set cert facts
  include_role:
    name: toni.certificates
    tasks_from: certbot_facts
  vars:
    certbot_server: "{{ nginx_subdomain }}{{ nginx_domain }}"
    record_dns_create: "{{ dns_create }}"
    record_dns_update: "{{ dns_update }}"

# .conf!!!
- name: Deploy vhost
  when: not existing_certs|bool and certbot_cert_exists|bool
  template:
    src: nginx.conf.j2
    dest: "{{ nginx_conf_dir }}/conf.d/{{ external_domain }}.conf"

- name: stop nginx stack
  when: nginx_stack_keep_alive|bool == false
  docker_stack:
    state: absent
    name: "{{ nginx_stack }}"
    compose:
      - "{{ user_path }}/{{ nginx_stack }}/docker-compose.yml"

- name: restart nginx stack
  when: nginx_stack_keep_alive|bool == false
  docker_stack:
    state: present
    prune: yes
    name: "{{ nginx_stack }}"
    compose:
      - "{{ user_path }}/{{ nginx_stack }}/docker-compose.yml"

- name: reload nginx stack
  command: make reload
  args:
    chdir: "{{ user_path }}/{{ nginx_stack }}"
  register: result_reload
  when: nginx_stack_keep_alive|bool == true

- name: Deploy compose file
  template:
    src: docker-compose.yml.j2
    dest: "{{ user_path }}/{{ deploy_name }}/docker-compose.yml"

- name: restart {{ deploy_name }} stack
  docker_stack:
    state: absent
    prune: yes
    name: "{{ deploy_name }}"
    compose:
      - "{{ user_path }}/{{ deploy_name }}/docker-compose.yml"

- name: restart {{ deploy_name }} stack
  docker_stack:
    state: present
    prune: yes
    name: "{{ deploy_name }}"
    compose:
      - "{{ user_path }}/{{ deploy_name }}/docker-compose.yml"

- name: reload nginx stack
  command: make reload
  args:
    chdir: "{{ user_path }}/{{ nginx_stack }}"
  register: result_reload
  when: nginx_stack_keep_alive|bool == true

- name: change app start configs 
  when: corteza_webapp_enable|bool == false
  include_tasks: dev.yml
  tags: [ never, dev]
  loop:
    - { app: "admin", port: "2400" }
    - { app: "one", port: "2401" }
    - { app: "compose", port: "2402" }
    - { app: "discovery", port: "2403" }
    - { app: "privacy", port: "2404" }
    - { app: "reporter", port: "2405" }
    - { app: "workflow", port: "2406" }

- name: Create Keycloak client
  include_role:
    name: toni.keycloak
    tasks_from: client
  vars:
    keycloak_role_name: "corteza"
  when: create_kc_client|default(false)

- name: Create Keycloak client role(s)
  include_role:
    name: toni.keycloak
    tasks_from: role
  vars:
    keycloak_role_name: "{{ item }}"
  when: create_kc_role|default(false)
  loop:
    "{{ keycloak_roles }}"

- name: Create Keycloak user(s)
  include_role:
    name: toni.keycloak
    tasks_from: user
  vars:
    kcu: "{{ kc_userdata }}"
  when: create_kc_user|default(false)
  loop:
    "{{ keycloak_users }}"
  loop_control:
    loop_var: kc_userdata

- name: Add role to user
  include_role:
    name: toni.keycloak
    tasks_from: clientrole
  vars:
    keycloak_username: "{{ kc_userdata.username }}"
    keycloak_role: 'corteza'
  when: create_kc_user|default(false)
  loop:
    "{{ keycloak_users }}"
  loop_control:
    loop_var: kc_userdata

#openresty temp hack
- name: Create Keycloak client role(s)
  include_role:
    name: toni.keycloak
    tasks_from: role
  vars:
    keycloak_role_name: "{{ item }}"
    ow_keycloak_client_name: "Nginx"
  when: create_kc_role|default(false)
  loop:
    "{{ keycloak_roles }}"

- name: Add role to user
  include_role:
    name: toni.keycloak
    tasks_from: clientrole
  vars:
    keycloak_username: "ace"
    ow_keycloak_client_name: "Nginx"
    keycloak_role: "corteza"

#- debug: var="{{ deploy_name }}_{{ deploy_name }}"
- name: wait for healthy Container
  shell: docker service ps -q -f desired-state=running "{{ deploy_name }}_{{ deploy_name }}" | xargs docker inspect --format \{\{.Status.ContainerStatus.ContainerID\}\} | xargs docker inspect --format \{\{.State.Health.Status\}\}
  register: result
  ignore_errors: true # result.rc=123 if service not known
  until: result.rc==0 and result.stdout == "healthy"
  retries: 18
  delay: 10
  #tags: [ never, app]
  #when: "'dev' not in ansible_run_tags"

# - name: Start corteza api
#   command: make corteza cmd=serve-api
#   args:
#     chdir: "{{ user_path }}/{{ deploy_name }}"
#   register: result_api
#   tags: [ never, dev]

# - name: Sleep for 180 seconds and continue with play // dev init needs container restart
#   wait_for:
#     timeout: 180
#   tags: [ never, dev] # dev needs startup script... so healthy can be tracked -> workaround
#   delegate_to: localhost

- name: Delete sink if exist
  file:
    state: absent
    path: "{{ user_path }}/{{ deploy_name }}/sink"
  when: enable_sink | bool == true

- name: generate sink route
  command: make sink #-B
  args:
    chdir: "{{ user_path }}/{{ deploy_name }}"
  register: result
  when: enable_sink | bool == true

- set_fact:
    sink{{ deploy_name }}: "{{ item.split('=')[1] }}"
  when: "enable_sink|bool == true and item.split('=')[0] == '/system/sink?__sign' and result.rc == 0"
  ignore_errors: true
  with_items: "{{ result.stderr_lines }}"

- copy: content="{{ vars['sink' + deploy_name ] }}" dest={{ user_path }}/{{ deploy_name }}/sink
  when: enable_sink | bool == true
  ignore_errors: true

- name: create backup daily backup by cron file under /etc/cron.d
  when: enable_backup | bool==true
  cron:
    name: Create {{ deploy_name }} backup
    minute: "0"
    hour: "4"
    user: root
    job: "make -C {{ user_path }}/{{ deploy_name }} completebackup"